{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JB6t1KDvgEsI"
      },
      "source": [
        "We became familiar with several ML techniques for Numeric prediction and Classification.\n",
        "\n",
        "In this activity we will use Artificial Neural Networks (ANN) for prediction and compare it with one of the techniques we used earlier for numeric predictions (linear regression)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43ONt2fUgmtr"
      },
      "source": [
        "# Numeric prediction using regression\n",
        "\n",
        "We will use the 50_startups dataset you are familiar with from activity 1."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "KSPMyFQSajop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5EvHk-ffyGP"
      },
      "source": [
        "#import dataset\n",
        "import pandas as pd\n",
        "df = pd.read_csv('50_Startups.csv')\n",
        "#defining input and outcome variables\n",
        "y = df[['Profit']]  #profit\n",
        "#X = dataset.drop(labels=['Profit','State'], axis=1) #other variables\n",
        "X = df.drop('Profit',axis=1) #other variables\n",
        "#add the binary encoded State variables to our X variable\n",
        "X=pd.concat([X,pd.get_dummies(X['State'])],axis=1)\n",
        "# drop the State column, since we now have the binary encoded vars\n",
        "X.drop(['State'],axis=1,inplace=True)\n",
        "df.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aN-agJcvikuw"
      },
      "source": [
        "y.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOWRyVHIhZ5Q"
      },
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)  #using same random_state value for replicability\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrM6lunzflDn"
      },
      "source": [
        "## Training a linear regression model with the train/test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHAp2OAGhb54"
      },
      "source": [
        "#### Fitting Multiple Linear Regression to the Training set  ####\n",
        "from sklearn.linear_model import LinearRegression\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train,Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4tchsFiyl0v"
      },
      "source": [
        "### Predictive performance of regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gV2zEckVhfdv"
      },
      "source": [
        "# Predicting the Test set results\n",
        "y_pred_lin = lin_reg.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTFw6aCny4G-"
      },
      "source": [
        "#model evaluation\n",
        "from sklearn import metrics\n",
        "import math\n",
        "print(\"Mean squared error: %.2f\" % (metrics.mean_squared_error(Y_test, y_pred_lin))) #MSE\n",
        "print(\"Root Mean squared error: %.2f\" % math.sqrt(metrics.mean_squared_error(Y_test, y_pred_lin))) #RMSE\n",
        "print(\"Mean absolute error: %.2f\" % metrics.mean_absolute_error(Y_test, y_pred_lin)) # mean absolute error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-89DyMYnfwad"
      },
      "source": [
        "## Training the Regression model using k-fold CV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfeH13b8nBOn"
      },
      "source": [
        "#training the regression model with k-fold Cross validation\n",
        "from sklearn import model_selection\n",
        "kfold = model_selection.KFold(n_splits=5) #our data has only 50 observations\n",
        "#we will output RMSE and MAE\n",
        "scoremetrics=('neg_root_mean_squared_error','neg_mean_absolute_error')\n",
        "for score in scoremetrics:\n",
        "  cv_results = model_selection.cross_val_score(lin_reg, X, y, cv=kfold, scoring=score)\n",
        "  msg = \"%s: %f (%f)\" % (score, -cv_results.mean(), cv_results.std())\n",
        "  print(msg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkh3afmAiFk6"
      },
      "source": [
        "#predict profit for a new startup (same dataset as in activity 2_numeric prediction)\n",
        "X_new=pd.read_csv('50_Startups_newinput.csv')\n",
        "print(X_new)\n",
        "lin_reg.predict(X_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skL7IthAiGeJ"
      },
      "source": [
        "# Using a Neural Network to predict numeric outcome (e.g., profit)\n",
        "\n",
        "Let's use an Artificial Neural Network (ANN) for the same problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWBH7lDCtD4d"
      },
      "source": [
        "#install some more things we need\n",
        "!pip install -q git+https://github.com/tensorflow/docs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hr04IeACiX3g"
      },
      "source": [
        "#if you have not loaded these yet...\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvCkuWHEqu3i"
      },
      "source": [
        "#%tensorflow_version 2.x\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAYIucfmq0fp"
      },
      "source": [
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.plots\n",
        "import tensorflow_docs.modeling"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4TzojoRsbsh"
      },
      "source": [
        "## Setting up the NN architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czX-k8cae0_f"
      },
      "source": [
        "# Just to make sure we have the right datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)\n",
        "#Our predictor/input variables\n",
        "X_train.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCLnVhapK4gQ"
      },
      "source": [
        "We define the following architecture for our ANN in the next cell and define it as a function:\n",
        "* 1 input layer with 6 nodes; equal to the number of predictor/input variables (take a look at X-train again)\n",
        "* 1 (or 2) fully-connected (dense) hidden layer with 64 (or 32) nodes\n",
        "we use the Rectifier Linear (ReLu) activation function for the nodes in the hiddern layer\n",
        "* 1 output layer with 1 node; since we have 1 continuous outcome variable\n",
        "\n",
        "Later on we will add another hidder layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Di7hQt02pyD"
      },
      "source": [
        "def build_model():\n",
        "  model = keras.Sequential([ #keras.Sequential creates a stack of layers (like a placeholder for layers we want to add)\n",
        "    layers.Dense(64, activation='relu', input_shape=[len(X_train.keys())]),\n",
        "    #layers.Dense(64, activation='relu'), #uncomment this line to add a 2nd hidden layer later\n",
        "    layers.Dense(1) # notice out output node does not have an activation function\n",
        "  ])\n",
        "\n",
        "  optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.005)\n",
        "\n",
        "  model.compile(loss='mse', #mean-square-error (MSE) is our loss function\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mae', 'mse']) #keep both MAE and MSE\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpEcTTHpZH9v"
      },
      "source": [
        "#NOTE:run this cell if you want to delete the model and clear tf session\n",
        "#tf.keras.backend.clear_session()\n",
        "#del model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwCXm286YhXl"
      },
      "source": [
        "#call the above function once to create our model (just initializing it)\n",
        "model=build_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUac5WipuzSe"
      },
      "source": [
        "# show model architecture (see below for details)\n",
        "model.summary()\n",
        "#Note: in dense_X  the number X merely keeps track of used layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_K7-2ZQXJyx3"
      },
      "source": [
        "For the above NN architecture (the one with one dense layer with 64 nodes), the number of parameters that can be trained are 448. How so?\n",
        "we have 1 parameter for each weight and 1 bias parameter for each node (except for our input nodes)\n",
        "*   6x64=384 (weights connecting each input node to each node in the hidden layer) +\n",
        "*   64 (bias parameter for nodes in the hidden layer)\n",
        "*   = 448 parameters\n",
        "*   64x1 (weights connecting each node in the hidden layer to the output node) +\n",
        "*   1 (bias parameter for output node) = 65 parameters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8YWqesrMGvE"
      },
      "source": [
        "### Question 1\n",
        "If we would use 32 nodes in the hidden layer (instead of 64), how many trainable parameters would the network have?\n",
        "\n",
        "You don't have to, but can change the network structure to have 32 nodes in the above cells and check the model architecture. If you o, make sure to change it back to 64 before proceeding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvH8WJhYNIRC"
      },
      "source": [
        "ans"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YacL_YFpTOQv"
      },
      "source": [
        "#let's take another look at our X-train dataset\n",
        "X_train.head(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzpRgqCJzvG0"
      },
      "source": [
        "#making sure we can feed our data to the NN\n",
        "model.predict((X_train[:10]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c32uG30JtEdt"
      },
      "source": [
        "## Training the NN model on unscaled data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 100\n",
        "history = model.fit(\n",
        "  X_train,Y_train,\n",
        "  epochs=EPOCHS, validation_split = 0.1, verbose=0, #in each epoch, 10% of the data is used as the validation set after the NN trains on the other 90%\n",
        "  callbacks=[tfdocs.modeling.EpochDots()])"
      ],
      "metadata": {
        "id": "bFzIqa4ucDzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ta3Zf2zGIFv"
      },
      "source": [
        "#take a look at the loss values for the first and last 5 epochs\n",
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist.head(5), hist.tail(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DU0tZ5lOeHV8"
      },
      "source": [
        "The MAE values are high!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzvdJ-KUsW5i"
      },
      "source": [
        "#using a plotter from tfdocs to visualize our NN's training\n",
        "plotter = tfdocs.plots.HistoryPlotter(smoothing_std=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFzL39TxGTAh"
      },
      "source": [
        "#plotting the error values per epoch; shows us how MAE goes down as network trains\n",
        "plotter.plot({'Basic': history}, metric = \"mae\")\n",
        "plt.ylim([0, 50000])\n",
        "#change the upper limit to roughly the MAE of your first epoch (from above cell)\n",
        "plt.ylabel('MAE [Profit]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq2lfGuHGvWG"
      },
      "source": [
        "#similar plot for MSE\n",
        "plotter.plot({'Basic': history}, metric = \"mse\")\n",
        "plt.ylim([0, 2e9])\n",
        "#change the upper limit to roughly the MSE of your first epoch (from above cell)\n",
        "plt.ylabel('MSE [Profit^2]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxoDH-OeCXFd"
      },
      "source": [
        "#another way to plot the Loss values per epoch (without using tensorflowDocs plotter)\n",
        "#no smoothing\n",
        "fig, axs = plt.subplots(ncols=2)\n",
        "fig.set_size_inches(15,4.5, forward=True)\n",
        "axs[0].plot(hist['epoch'], hist[\"mae\"])\n",
        "axs[0].plot(hist['epoch'], hist[\"val_mae\"])\n",
        "axs[0].legend(['Training loss','Test loss'])\n",
        "axs[0].set_title('MAE [Profit]')\n",
        "axs[0].grid()\n",
        "axs[1].plot(hist['epoch'], hist[\"mse\"])\n",
        "axs[1].plot(hist['epoch'], hist[\"val_mse\"])\n",
        "axs[1].legend(['Training loss','Test loss'])\n",
        "axs[1].set_title('MSE [Profit^2]')\n",
        "axs[1].grid()\n",
        "plt.plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n29Q0cE8e8GS"
      },
      "source": [
        "Notice the values in both plots are high, but converge after epoch 20\n",
        "\n",
        "https://machinelearningmastery.com/learning-curves-for-diagnosing-machine-learning-model-performance/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoJrosl7yTVV"
      },
      "source": [
        "### NN model performance (trained on unscaled data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qy4y8m2iVcjp"
      },
      "source": [
        "# let's evalute the trained NN on out test data (X_test)\n",
        "y_pred=model.predict(X_test)\n",
        "from sklearn import metrics\n",
        "import math\n",
        "#print('Coefficients: \\n', lin_reg.coef_) #regression coefficients\n",
        "print(\"Root Mean squared error: %.2f\" % math.sqrt(metrics.mean_squared_error(Y_test, y_pred))) #RMSE\n",
        "print(\"Mean absolute error: %.2f\" % metrics.mean_absolute_error(Y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6vospy_fS5u"
      },
      "source": [
        "### Question 2\n",
        "Does the NN model have a better predictive performance than the regression model?\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5FIgvaQdLw1"
      },
      "source": [
        "## Train the NN model on scaled data (this is the right way)\n",
        "Now we will train the model on the scaled data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kA-90qb8dLFY"
      },
      "source": [
        "#NOTE:this cell deletes the model and clears tf session\n",
        "tf.keras.backend.clear_session()\n",
        "del model\n",
        "#delete the model to not keep any of the learned weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1W8KHoqbgrEz"
      },
      "source": [
        "#build same model again and\n",
        "model=build_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haZ4dZXtVFWq"
      },
      "source": [
        "# Feature Scaling, we will use MinMax scaling\n",
        "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
        "sc_X = StandardScaler()\n",
        "sc_Y = StandardScaler()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao84Yq2mg6OO"
      },
      "source": [
        "#training the NN on scaled data (NOTE: this is the right way!)\n",
        "EPOCHS = 100\n",
        "history = model.fit(\n",
        "  sc_X.fit_transform(X_train),sc_Y.fit_transform(Y_train),\n",
        "  epochs=EPOCHS, validation_split = 0.1, verbose=0, #in each epoch, 10% of the data is used as the validation set after the NN trains on the other 90%\n",
        "  callbacks=[tfdocs.modeling.EpochDots()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_ZD4GOEhUvA"
      },
      "source": [
        "#take a look at the loss values for the first and last 5 epochs\n",
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist.head(5), hist.tail(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3lHZJ_mhgWu"
      },
      "source": [
        "#plotting the error values per epoch; shows us how MAE goes down as network trains\n",
        "plotter = tfdocs.plots.HistoryPlotter(smoothing_std=2)\n",
        "plotter.plot({'Basic': history}, metric = \"mae\")\n",
        "#plt.ylim([0, 0.3])\n",
        "#change the upper limit to roughly the MAE of your first epoch (from above cell)\n",
        "plt.ylabel('MAE [Profit]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB7wkBadrMcT"
      },
      "source": [
        "#similar plot for MSE\n",
        "plotter.plot({'Basic': history}, metric = \"mse\")\n",
        "plt.ylim([0, 0.15])\n",
        "#change the upper limit to roughly the MSE of your first epoch (from above cell)\n",
        "plt.ylabel('MSE [Profit^2]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WaQMWaGhqY5"
      },
      "source": [
        "#another way to plot the Loss values per epoch (without using tensorflowDocs plotter)\n",
        "#no smoothing\n",
        "fig, axs = plt.subplots(ncols=2)\n",
        "fig.set_size_inches(15,4.5, forward=True)\n",
        "axs[0].plot(hist['epoch'], hist[\"mae\"])\n",
        "axs[0].plot(hist['epoch'], hist[\"val_mae\"])\n",
        "axs[0].legend(['Training loss','Test loss'])\n",
        "axs[0].set_title('MAE [Profit]')\n",
        "axs[0].grid()\n",
        "axs[1].plot(hist['epoch'], hist[\"mse\"])\n",
        "axs[1].plot(hist['epoch'], hist[\"val_mse\"])\n",
        "axs[1].legend(['Training loss','Test loss'])\n",
        "axs[1].set_title('MSE [Profit^2]')\n",
        "axs[1].grid()\n",
        "plt.plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wN5syYa7uAfL"
      },
      "source": [
        "### Question 3\n",
        "At around which epoch (approximately) does the model not improve anymore?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhHF2O5JyZjA"
      },
      "source": [
        "### NN model performance (trained on scaled data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-1L5nmk74Z3"
      },
      "source": [
        "from sklearn import metrics\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2p4WENhUALi_"
      },
      "source": [
        "Since we have trained the NN on scaled X_train, we need to scale the test data before feeding it to the trained NN model for predictions\n",
        "\n",
        "Similarly, the resulting NN model predictions (*y_pred*) are scaled and we need to transform it back to its original scale (*sc_Y.inverse_transform(y_pred)* ) for a meaningful comparison with Y_test (profit values on the original scale in our test data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3Jj8NpM01OD"
      },
      "source": [
        "# let's evaluate the trained NN model\n",
        "# we need to scale the test data since we have trained the NN on scaled X\n",
        "y_pred=model.predict(sc_X.transform(X_test))\n",
        "\n",
        "print(\"RMSE: %.2f\" % math.sqrt(metrics.mean_squared_error(Y_test, sc_Y.inverse_transform(y_pred)))) #RMSE\n",
        "print(\"MAE: %.2f\" % metrics.mean_absolute_error(Y_test, sc_Y.inverse_transform(y_pred))) #MAE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eReU61B66c56"
      },
      "source": [
        "sc_Y.inverse_transform(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmrlSMikBJ-v"
      },
      "source": [
        "Notice that the NN model's performance improves when we (correctly) train it on the scaled data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDzRPKQbuNKQ"
      },
      "source": [
        "# let's look at the metrics using the scaled outcome variable (Profit)\n",
        "print(\"RMSE: %.2f\" % math.sqrt(metrics.mean_squared_error(sc_Y.transform(Y_test), y_pred))) #RMSE\n",
        "print(\"MAE: %.2f\" % metrics.mean_absolute_error(sc_Y.transform(Y_test), y_pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g84ftlzR--2i"
      },
      "source": [
        "Remember RMSE and MAE are in the same unit as the outcome variable. So when we evaluate the model on the scaled Profit (i.e., profit ranges from 0 to 1) the RMSE and MAE values are naturally smaller. But we can't really interpret them in terms of dollar values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSjgIsa72wE8"
      },
      "source": [
        "## Comparing performance against Regression model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0dHkB2w8Dzg"
      },
      "source": [
        "print(\"RMSE NN model: %.2f\" % math.sqrt(metrics.mean_squared_error(Y_test, sc_Y.inverse_transform(y_pred)))) #RMSE\n",
        "print(\"MAE NN model: %.2f\" % metrics.mean_absolute_error(Y_test, sc_Y.inverse_transform(y_pred)) +\"\\n\") #MAE\n",
        "\n",
        "print(\"RMSE linear regression: %.2f\" % math.sqrt(metrics.mean_squared_error(Y_test, y_pred_lin))) #RMSE\n",
        "print(\"MAE linear regression: %.2f\" % metrics.mean_absolute_error(Y_test, y_pred_lin))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LdJgxNQBCO1"
      },
      "source": [
        "### Question 4\n",
        "As you can see, in our example the NN model performs worse than the Regression model. Why?\n",
        "\n",
        "This is because we have a very small dataset; 50 observations and we use 40 of them for training. NNs performs well on large data, here our NN is \"learning\" (adjusting all those parameters) based on a very limited number of observations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqDATjPND_Kp"
      },
      "source": [
        "# Using a Neural network like a regression?!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wG-kOHyuENPs"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PG_SDU8__OUj"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "del model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRdpGq4M-7Vq"
      },
      "source": [
        "def build_model():\n",
        "  model = keras.Sequential([ #keras.Sequential creates a stack of layers (like a placeholder for layers we want to add)\n",
        "    layers.Dense(units=1,activation=None, input_shape=[len(X_train.keys())])\n",
        "  ])\n",
        "\n",
        "  optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.005)\n",
        "\n",
        "  model.compile(loss='mse', #mean-square-error (MSE) is our loss function\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mae', 'mse']) #keep both MAE and MSE\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPtlQf3m_Rfb"
      },
      "source": [
        "model=build_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJl6ItzR_jWl"
      },
      "source": [
        "#training on unscaled data\n",
        "EPOCHS = 100\n",
        "history = model.fit(\n",
        "  X_train,Y_train,\n",
        "  epochs=EPOCHS, validation_split = 0.1, verbose=0, #in each epoch, 10% of the data is used as the validation set after the NN trains on the other 90%\n",
        "  callbacks=[tfdocs.modeling.EpochDots()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tRpuAub_rNJ"
      },
      "source": [
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "\n",
        "fig, axs = plt.subplots(ncols=2)\n",
        "fig.set_size_inches(15,4.5, forward=True)\n",
        "axs[0].plot(hist['epoch'], hist[\"mae\"])\n",
        "axs[0].plot(hist['epoch'], hist[\"val_mae\"])\n",
        "axs[0].legend(['Training loss','Test loss'])\n",
        "axs[0].set_title('MAE [Profit]')\n",
        "axs[0].grid()\n",
        "axs[1].plot(hist['epoch'], hist[\"mse\"])\n",
        "axs[1].plot(hist['epoch'], hist[\"val_mse\"])\n",
        "axs[1].legend(['Training loss','Test loss'])\n",
        "axs[1].set_title('MSE [Profit^2]')\n",
        "axs[1].grid()\n",
        "plt.plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnjQ823B_3Ak"
      },
      "source": [
        "y_pred=model.predict(X_test)\n",
        "print(\"Root Mean squared error: %.2f\" % math.sqrt(metrics.mean_squared_error(Y_test, y_pred))) #RMSE\n",
        "print(\"Mean absolute error: %.2f\" % metrics.mean_absolute_error(Y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CsOvJj1_mZs"
      },
      "source": [
        "#training on scaled data\n",
        "EPOCHS = 300\n",
        "history = model.fit(\n",
        "  sc_X.fit_transform(X_train),sc_Y.fit_transform(Y_train),\n",
        "  epochs=EPOCHS, validation_split = 0.1, verbose=0, #in each epoch, 10% of the data is used as the validation set after the NN trains on the other 90%\n",
        "  callbacks=[tfdocs.modeling.EpochDots()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL8lWtK5ALu6"
      },
      "source": [
        "y_pred=model.predict(sc_X.transform(X_test))\n",
        "\n",
        "print(\"RMSE: %.2f\" % math.sqrt(metrics.mean_squared_error(Y_test, sc_Y.inverse_transform(y_pred)))) #RMSE\n",
        "print(\"MAE: %.2f\" % metrics.mean_absolute_error(Y_test, sc_Y.inverse_transform(y_pred))) #MAE"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}